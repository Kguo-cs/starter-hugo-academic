
@InProceedings{pmlr-v229-liu23f,
  title = 	 {TraCo: Learning Virtual Traffic Coordinator for Cooperation with Multi-Agent Reinforcement Learning},
  author =       {Liu, Weiwei and Jing, Wei and Gao, lingping and Guo, Ke and Xu, Gang and Liu, Yong},
  booktitle = 	 {Proceedings of The 7th Conference on Robot Learning},
  pages = 	 {2465--2477},
  year = 	 {2023},
  editor = 	 {Tan, Jie and Toussaint, Marc and Darvish, Kourosh},
  volume = 	 {229},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--09 Nov},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v229/liu23f/liu23f.pdf},
  url = 	 {https://proceedings.mlr.press/v229/liu23f.html},
  abstract = 	 {Multi-agent reinforcement learning (MARL) has emerged as a popular technique in diverse domains due to its ability to automate system controller design and facilitate continuous intelligence learning. For instance, traffic flow is often trained with MARL to enable intelligent simulations for autonomous driving. However, The existing MARL algorithm only characterizes the relative degree of each agentâ€™s contribution to the team, and cannot express the contribution that the team needs from the agent. Especially in the field of autonomous driving, the team changes over time, and the agent needs to act directly according to the needs of the team. To address these limitations, we propose an innovative method inspired by realistic traffic coordinators called the Traffic Coordinator Network (TraCo). Our approach leverages a combination of cross-attention and counterfactual advantage function, allowing us to extract distinctive characteristics of domain agents and accurately quantify the contribution that a team needs from an agent. Through experiments conducted on four traffic tasks, we demonstrate that our method outperforms existing approaches, yielding superior performance. Furthermore, our approach enables the emergence of rich and diverse social behaviors among vehicles within the traffic flow.}
}

